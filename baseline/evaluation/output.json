import os
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import json
from torch.optim import AdamW
from torch.utils.data import DataLoader, Dataset

# 初始化处理器和模型
processor = BlipProcessor.from_pretrained("Salesforce/blip2-flan-t5-xl")
model = BlipForConditionalGeneration.from_pretrained(
    "Salesforce/blip2-flan-t5-xl", ignore_mismatched_sizes=True
).to("cuda")

# 设置优化器
optimizer = AdamW(model.parameters(), lr=5e-5)

# 路径设置
qa_json_path = "/path/to/qa.json"  # 替换为你的 qa.json 文件路径
frame_base_path = "/path/to/frames/"  # 替换为你的图像根目录路径

# 加载 JSON 数据
with open(qa_json_path, "r") as f:
    qa_data = json.load(f)


# 自定义数据集
class QADataset(Dataset):
    def __init__(self, qa_data, frame_base_path):
        self.qa_data = qa_data
        self.frame_base_path = frame_base_path

    def __len__(self):
        return len(self.qa_data)

    def __getitem__(self, idx):
        data = self.qa_data[idx]
        question = data["question"]
        answer = data["answer"]
        frame_id = data["frame"]

        # 加载该 frame 下的所有图片
        images = self.load_images_from_frame(frame_id)

        return question, answer, images

    def load_images_from_frame(self, frame_id):
        images = []
        frame_path = os.path.join(self.frame_base_path, frame_id)
        for img_name in os.listdir(frame_path):
            img_path = os.path.join(frame_path, img_name)
            if img_path.endswith((".jpg", ".png")):
                try:
                    img = Image.open(img_path).convert("RGB")
                    images.append(img)
                except Exception as e:
                    print(f"Error loading image {img_path}: {e}")
        return images


# 定义数据加载器
def collate_fn(batch):
    questions, answers, images_list = zip(*batch)

    # 将每组的多张图片进行处理，合并到一个批次
    batched_pixel_values = []
    for images in images_list:
        pixel_values = processor(images=images, return_tensors="pt", padding=True).pixel_values
        batched_pixel_values.append(pixel_values)

    # 合并图像维度
    batched_pixel_values = torch.cat(batched_pixel_values, dim=0)

    # 文本处理
    input_ids = processor(list(questions), return_tensors="pt", padding=True, truncation=True).input_ids
    labels = processor(list(answers), return_tensors="pt", padding=True, truncation=True).input_ids

    return input_ids, labels, batched_pixel_values


dataset = QADataset(qa_data, frame_base_path)
dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)


# 训练循环
num_epochs = 5
for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    for batch in dataloader:
        input_ids, labels, pixel_values = batch

        input_ids = input_ids.to("cuda")
        labels = labels.to("cuda")
        pixel_values = pixel_values.to("cuda")

        # 模型前向计算
        outputs = model(input_ids=input_ids, labels=labels, pixel_values=pixel_values)
        loss = outputs.loss
        total_loss += loss.item()

        # 反向传播和优化
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

    print(f"Epoch {epoch+1}/{num_epochs} completed. Total Loss: {total_loss:.4f}")

    # 保存模型
    model.save_pretrained(f"./blip2_flan_t5_epoch_{epoch+1}")
    processor.save_pretrained(f"./blip2_flan_t5_epoch_{epoch+1}")
    print(f"Model and processor saved for epoch {epoch+1}.")
