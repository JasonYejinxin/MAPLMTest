import os
import json
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import BlipForConditionalGeneration, BlipProcessor, AdamW
import torch.nn.functional as F

# 数据集类
class CustomDataset(Dataset):
    def __init__(self, data_folder, qa_file, processor, device):
        self.data_folder = data_folder
        self.qa_data = self._load_qa_data(qa_file)
        self.processor = processor
        self.device = device

    def _load_qa_data(self, qa_file):
        with open(qa_file, 'r') as f:
            return json.load(f)

    def __len__(self):
        return len(self.qa_data)

    def __getitem__(self, idx):
        entry = self.qa_data[idx]
        frame = entry["frame"]
        question = entry["question"]
        answer = entry["answer"]

        # 获取对应的图片路径
        image_paths = [os.path.join(self.data_folder, frame, img) for img in os.listdir(os.path.join(self.data_folder, frame))]

        # 处理图片特征
        image_features = []
        for img_path in image_paths:
            image = self.processor.image_processor(img_path)
            image_features.append(image)
        
        # 合并图片特征：例如我们可以对4张图片的特征进行平均
        image_features = torch.stack(image_features).to(self.device)  # 确保数据在正确的设备上
        image_features = image_features.mean(dim=0)  # 取4张图像的特征均值作为该组的图像特征

        return {
            "image_features": image_features,
            "question": question,
            "answer": answer
        }

# 逐步加载模型权重
def load_model_with_partial_weights(model_name="Salesforce/blip2-flan-t5-xl", device="cuda"):
    processor = BlipProcessor.from_pretrained(model_name)
    model = BlipForConditionalGeneration.from_pretrained(model_name, ignore_mismatched_sizes=True)
    model.to(device)  # 确保模型在正确的设备上
    return processor, model

# 定义训练过程
def train_model(data_folder, qa_file, output_dir, model_name="Salesforce/blip2-flan-t5-xl", epochs=5, batch_size=4, learning_rate=1e-5):
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # 加载处理器和模型
    processor, model = load_model_with_partial_weights(model_name, device)
    
    # 初始化数据集和数据加载器
    dataset = CustomDataset(data_folder, qa_file, processor, device)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # 定义优化器
    optimizer = AdamW(model.parameters(), lr=learning_rate)

    # 开始训练
    model.train()
    for epoch in range(epochs):
        for batch in dataloader:
            image_features = batch["image_features"].to(device)  # 确保图片特征在正确的设备上
            question = batch["question"]
            answer = batch["answer"]

            # 处理输入文本
            inputs = processor(text=question, return_tensors="pt", padding=True, truncation=True).to(device)  # 确保文本数据在正确的设备上
            labels = processor.tokenizer(answer, return_tensors="pt", padding=True, truncation=True).input_ids.to(device)  # 同样要移到设备上

            outputs = model(
                pixel_values=image_features,
                input_ids=inputs.input_ids,
                attention_mask=inputs.attention_mask,
                labels=labels
            )

            loss = outputs.loss
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            print(f"Epoch {epoch + 1}, Loss: {loss.item()}")

    # 保存模型
    os.makedirs(output_dir, exist_ok=True)
    model.save_pretrained(output_dir)
    processor.save_pretrained(output_dir)
    print(f"Model saved to {output_dir}")

# 主函数
if __name__ == "__main__":
    data_folder = "/path/to/train"  # 替换为图片文件夹路径
    qa_file = "/path/to/qa.json"  # 替换为 QA 文件路径
    output_dir = "/path/to/output"  # 替换为模型保存路径

    train_model(data_folder, qa_file, output_dir)
