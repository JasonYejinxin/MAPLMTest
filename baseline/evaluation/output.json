import os
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import json
from torch.optim import AdamW

# 初始化 BLIP 处理器和模型
processor = BlipProcessor.from_pretrained("Salesforce/blip2-flan-t5-xl")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip2-flan-t5-xl").to("cuda")

# 设置优化器
optimizer = AdamW(model.parameters(), lr=5e-5)

# 假设qa.json文件是存储在当前目录下
qa_json_path = "/path/to/qa.json"  # 替换为你的qa.json文件路径
with open(qa_json_path, 'r') as f:
    qa_data = json.load(f)

# 载入图像
def load_images_from_frame(frame_id):
    images = []
    frame_path = os.path.join("/path/to/train", frame_id)  # 指定图片路径
    for img_name in os.listdir(frame_path):
        img_path = os.path.join(frame_path, img_name)
        if img_path.endswith('.jpg') or img_path.endswith('.png'):
            img = Image.open(img_path).convert("RGB")
            images.append(img)
    return images

# 处理图像和文本数据
def process_multimodal_data(qa_data):
    inputs = []
    targets = []

    for data in qa_data:
        question = data["question"]
        frame = data["frame"]
        answer = data["answer"]

        # 加载该 frame 下的四张图片
        images = load_images_from_frame(frame)
        
        # 提取图像特征
        pixel_values = processor(images=images, return_tensors="pt").pixel_values.to("cuda")
        
        # 将问题转化为输入 ID
        text_inputs = processor(text=question, return_tensors="pt").input_ids.to("cuda")

        # 处理图像和文本的联合输入
        outputs = model(input_ids=text_inputs, pixel_values=pixel_values)

        # 处理模型输出，通常是生成答案
        generated_answer = processor.decode(outputs.logits.argmax(dim=-1), skip_special_tokens=True)
        
        # 保存输入和目标
        inputs.append(question)
        targets.append(generated_answer)

    return inputs, targets

# 训练模型时使用的输入和目标
inputs, targets = process_multimodal_data(qa_data)

# 训练循环
for epoch in range(5):  # 假设训练 5 个 epoch
    model.train()
    for i in range(len(inputs)):
        input_ids = processor(inputs[i], return_tensors="pt").input_ids.to("cuda")
        target_ids = processor(targets[i], return_tensors="pt").input_ids.to("cuda")
        
        # 向模型传递输入和目标
        outputs = model(input_ids=input_ids, labels=target_ids)
        
        loss = outputs.loss
        loss.backward()

        # 更新权重
        optimizer.step()
        optimizer.zero_grad()

    print(f"Epoch {epoch+1} completed. Loss: {loss.item()}")

    # 保存模型
    model.save_pretrained(f"./blip2_flan_t5_epoch_{epoch+1}")
    processor.save_pretrained(f"./blip2_flan_t5_epoch_{epoch+1}")

    print(f"Model and processor saved for epoch {epoch+1}.")
